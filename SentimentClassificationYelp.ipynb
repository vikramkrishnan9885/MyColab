{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentClassificationYelp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOlff/hfnI4M7tysbsd44oZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4077f5c5e44746f28ad422c6518eb5f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7ced6313fb5945748b666d2de08d158a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4865f7a04d2546e5920d1e5901875729",
              "IPY_MODEL_9e5a7771dac244e68d97783ddfca88bd"
            ]
          }
        },
        "7ced6313fb5945748b666d2de08d158a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4865f7a04d2546e5920d1e5901875729": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_856c668c0cc64e56a4a9cf2ed7078f71",
            "_dom_classes": [],
            "description": "training routine:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5f5b053a4ebe4c79903ae64a028ce42d"
          }
        },
        "9e5a7771dac244e68d97783ddfca88bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fc6e7d61af014dd7961b607942b7b7c0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/100 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_59734f5c209b4563925b72c8495efaab"
          }
        },
        "856c668c0cc64e56a4a9cf2ed7078f71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5f5b053a4ebe4c79903ae64a028ce42d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc6e7d61af014dd7961b607942b7b7c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "59734f5c209b4563925b72c8495efaab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b8fbd1abaf64cacbd21b828a0ac1016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_09e78ba9c5234e3982e41139ddfe3167",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9d9d60871ed34472af0b3ff46f81d8e6",
              "IPY_MODEL_bcb24122ac264f80875e923420e33957"
            ]
          }
        },
        "09e78ba9c5234e3982e41139ddfe3167": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9d9d60871ed34472af0b3ff46f81d8e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_56f126cd5ca148c4b60a47779bc68a07",
            "_dom_classes": [],
            "description": "split=train:   1%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 392000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2916,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5e8241a070124ba3ba7bfb07a7817db4"
          }
        },
        "bcb24122ac264f80875e923420e33957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cc17b1452dca4dbea21c74d6af1ba6e4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2916/392000 [02:10&lt;4:54:22, 22.03it/s, acc=91.2, epoch=0, loss=0.268]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_56466eec01ee4ca090fa3615707cd020"
          }
        },
        "56f126cd5ca148c4b60a47779bc68a07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5e8241a070124ba3ba7bfb07a7817db4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc17b1452dca4dbea21c74d6af1ba6e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "56466eec01ee4ca090fa3615707cd020": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "13932c5ee63a46299660c8ab70012852": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_97dc381f0dda43da9c666370ed4be383",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e9d39a028b934991be17f929d1dfc0a3",
              "IPY_MODEL_e18de12173e44ea1a6821b7c3215607f"
            ]
          }
        },
        "97dc381f0dda43da9c666370ed4be383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e9d39a028b934991be17f929d1dfc0a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7d107b957c8f400e9c5b140cfd313d3e",
            "_dom_classes": [],
            "description": "split=val:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 168000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_70bbd740458246cbacdcd9f2bef437d2"
          }
        },
        "e18de12173e44ea1a6821b7c3215607f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2d07d1b1141e42f79f7ebfc87fda2aa2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/168000 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_beec5446dcda464db642ad268bbe72c4"
          }
        },
        "7d107b957c8f400e9c5b140cfd313d3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "70bbd740458246cbacdcd9f2bef437d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d07d1b1141e42f79f7ebfc87fda2aa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "beec5446dcda464db642ad268bbe72c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vikramkrishnan9885/MyColab/blob/master/SentimentClassificationYelp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG_N4s9txX6b",
        "colab_type": "text"
      },
      "source": [
        "# Data Handling\n",
        "\n",
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyC1cmp6yL6d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "\n",
        "def progress_bar(some_iter):\n",
        "    try:\n",
        "        from tqdm import tqdm\n",
        "        return tqdm(some_iter)\n",
        "    except ModuleNotFoundError:\n",
        "        return some_iter\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    print(\"Trying to fetch {}\".format(destination))\n",
        "\n",
        "    def get_confirm_token(response):\n",
        "        for key, value in response.cookies.items():\n",
        "            if key.startswith('download_warning'):\n",
        "                return value\n",
        "\n",
        "        return None\n",
        "\n",
        "    def save_response_content(response, destination):\n",
        "        CHUNK_SIZE = 32768\n",
        "\n",
        "        with open(destination, \"wb\") as f:\n",
        "            for chunk in progress_bar(response.iter_content(CHUNK_SIZE)):\n",
        "                if chunk: # filter out keep-alive new chunks\n",
        "                    f.write(chunk)\n",
        "\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJVD96rJyfDl",
        "colab_type": "text"
      },
      "source": [
        "## Download Yelp dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p867A03MzFNt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        },
        "outputId": "898d4cea-ba30-4a8b-8a78-d3841b36bbf5"
      },
      "source": [
        "file_id_0 = '1xeUnqkhuzGGzZKThzPeXe2Vf6Uu_g_xM'\n",
        "destination_0 = 'yelp_raw_train.csv'\n",
        "download_file_from_google_drive(file_id_0, destination_0)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trying to fetch yelp_raw_train.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12536it [00:04, 2575.87it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_dvnpiIzGz0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        },
        "outputId": "cd1f5357-6ea0-4166-cb42-56d180129fce"
      },
      "source": [
        "file_id_1 = '1G42LXv72DrhK4QKJoFhabVL4IU6v2ZvB'\n",
        "destination_1 = 'yelp_raw_test.csv'\n",
        "download_file_from_google_drive(file_id_1, destination_1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trying to fetch yelp_raw_test.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "848it [00:00, 4151.15it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9b2MdqazvM1",
        "colab_type": "text"
      },
      "source": [
        "## Data munging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qg43IyC0z8Kw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "from argparse import Namespace"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3pPICNf2zsm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args = Namespace(\n",
        "    raw_train_dataset_csv=\"yelp_raw_train.csv\",\n",
        "    raw_test_dataset_csv=\"yelp_raw_test.csv\",\n",
        "    train_proportion=0.7,\n",
        "    val_proportion=0.3,\n",
        "    output_munged_csv=\"yelp_with_splits_full.csv\",\n",
        "    seed=1337\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Qp7jZaM2-k7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read raw data\n",
        "train_reviews = pd.read_csv(args.raw_train_dataset_csv, header=None, names=['rating', 'review'])\n",
        "train_reviews = train_reviews[~pd.isnull(train_reviews.review)]\n",
        "test_reviews = pd.read_csv(args.raw_test_dataset_csv, header=None, names=['rating', 'review'])\n",
        "test_reviews = test_reviews[~pd.isnull(test_reviews.review)]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McnnTHqy3H5x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1808ecb9-3b0b-4b60-89ed-f493caf0ed03"
      },
      "source": [
        "train_reviews.head(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Unfortunately, the frustration of being Dr. Go...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Been going to Dr. Goldberg for over 10 years. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>I'm writing this review to give you a heads up...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>All the food is great here. But the best thing...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rating                                             review\n",
              "0       1  Unfortunately, the frustration of being Dr. Go...\n",
              "1       2  Been going to Dr. Goldberg for over 10 years. ...\n",
              "2       1  I don't know what Dr. Goldberg was like before...\n",
              "3       1  I'm writing this review to give you a heads up...\n",
              "4       2  All the food is great here. But the best thing..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRXC13Lt3KQb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8da48e20-d916-4ab4-f200-d53204d6e8dd"
      },
      "source": [
        "test_reviews.head(5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Ordered a large Mango-Pineapple smoothie. Stay...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Quite a surprise!  \\n\\nMy wife and I loved thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>First I will say, this is a nice atmosphere an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>I was overall pretty impressed by this hotel. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Video link at bottom review. Worst service I h...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rating                                             review\n",
              "0       1  Ordered a large Mango-Pineapple smoothie. Stay...\n",
              "1       2  Quite a surprise!  \\n\\nMy wife and I loved thi...\n",
              "2       1  First I will say, this is a nice atmosphere an...\n",
              "3       2  I was overall pretty impressed by this hotel. ...\n",
              "4       1  Video link at bottom review. Worst service I h..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxVUOAHC3MhF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "6d6bf10e-b3ed-456d-d7b4-51eff352ad2c"
      },
      "source": [
        "# Unique classes\n",
        "set(train_reviews.rating)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1, 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suIdlIfW684k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting train by rating\n",
        "# Create dict\n",
        "by_rating = collections.defaultdict(list)\n",
        "for _, row in train_reviews.iterrows():\n",
        "    by_rating[row.rating].append(row.to_dict())"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cl2W3Azk7AbB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create split data\n",
        "final_list = []\n",
        "np.random.seed(args.seed)\n",
        "\n",
        "for _, item_list in sorted(by_rating.items()):\n",
        "\n",
        "    np.random.shuffle(item_list)\n",
        "    \n",
        "    n_total = len(item_list)\n",
        "    n_train = int(args.train_proportion * n_total)\n",
        "    n_val = int(args.val_proportion * n_total)\n",
        "    \n",
        "    # Give data point a split attribute\n",
        "    for item in item_list[:n_train]:\n",
        "        item['split'] = 'train'\n",
        "    \n",
        "    for item in item_list[n_train:n_train+n_val]:\n",
        "        item['split'] = 'val'\n",
        "\n",
        "    # Add to final list\n",
        "    final_list.extend(item_list)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d50DSnSs7C_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for _, row in test_reviews.iterrows():\n",
        "    row_dict = row.to_dict()\n",
        "    row_dict['split'] = 'test'\n",
        "    final_list.append(row_dict)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QHjCMpc7IQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write split data to file\n",
        "final_reviews = pd.DataFrame(final_list)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkM3Au9-7KY7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "5c4c07f3-aedd-40c3-9d1a-c53de8a35536"
      },
      "source": [
        "final_reviews.split.value_counts()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "train    392000\n",
              "val      168000\n",
              "test      38000\n",
              "Name: split, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-t6xlmL7NLe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "36f6c7bb-b347-412b-be50-d8cff5b494ca"
      },
      "source": [
        "final_reviews.review.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    The entrance was the #1 impressive thing about...\n",
              "1    I'm a Mclover, and I had no problem\\nwith the ...\n",
              "2    Less than good here, not terrible, but I see n...\n",
              "3    I don't know if I can ever bring myself to go ...\n",
              "4    Food was OK/Good but the service was terrible....\n",
              "Name: review, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVjsgefi7PgK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "baf681cd-a26e-4bde-9738-40c5f40f3b22"
      },
      "source": [
        "final_reviews[pd.isnull(final_reviews.review)]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>review</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [rating, review, split]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64002uvY7SPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_text(text):\n",
        "    if type(text) == float:\n",
        "        print(text)\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"([.,!?])\", r\" \\1 \", text)\n",
        "    text = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", text)\n",
        "    return text\n",
        "    \n",
        "final_reviews.review = final_reviews.review.apply(preprocess_text)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0w74FwFP7WEE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f2b24e30-386f-434a-b5ec-b63b9dc3eae2"
      },
      "source": [
        "final_reviews['rating'] = final_reviews.rating.apply({1: 'negative', 2: 'positive'}.get)\n",
        "final_reviews.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>review</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>negative</td>\n",
              "      <td>the entrance was the impressive thing about th...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>negative</td>\n",
              "      <td>i m a mclover , and i had no problem nwith the...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>less than good here , not terrible , but i see...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>i don t know if i can ever bring myself to go ...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>food was ok good but the service was terrible ...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     rating                                             review  split\n",
              "0  negative  the entrance was the impressive thing about th...  train\n",
              "1  negative  i m a mclover , and i had no problem nwith the...  train\n",
              "2  negative  less than good here , not terrible , but i see...  train\n",
              "3  negative  i don t know if i can ever bring myself to go ...  train\n",
              "4  negative  food was ok good but the service was terrible ...  train"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H3czZMd7baQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_reviews.to_csv(args.output_munged_csv, index=False)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUeDTO8s7eO8",
        "colab_type": "text"
      },
      "source": [
        "# Classification\n",
        "\n",
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJV7vi7e72Ui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from argparse import Namespace\n",
        "from collections import Counter\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm_notebook"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1AGtcq377pm",
        "colab_type": "text"
      },
      "source": [
        "After understanding the dataset, you will see a pattern defining three assisting classes that is repeated throughout this book and is used to transform text data into a vectorized form: \n",
        "  * the Vocabulary, \n",
        "  * the Vectorizer, and \n",
        "  * PyTorch’s DataLoader. \n",
        "  \n",
        "The __Vocabulary__ coordinates the __integer-to-token mappings__ that we discussed in \"Observation and Target Encoding\". We use a Vocabulary both for mapping the __text tokens to integers__ and for mapping the __class labels to integers__. \n",
        "\n",
        "Next, the __Vectorizer__ __encapsulates the vocabularies__ and is responsible for __ingesting string data__, like a review’s text, and __converting it to numerical vectors__ that will be used in the training routine. \n",
        "\n",
        "We use the final assisting class, PyTorch’s DataLoader, __to group and collate the individual vectorized data points into minibatches__."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KZIhApF-2i5",
        "colab_type": "text"
      },
      "source": [
        "## Data Vectorization classes\n",
        "\n",
        "### Vocabulary\n",
        "\n",
        "The first stage in going from text to vectorized minibatch is to __map each token to a numerical version__ of itself. \n",
        "\n",
        "The standard methodology is to have a __bijection__—a mapping that can be reversed—between the tokens and integers. In Python, this is simply two dictionaries. We encapsulate this bijection into a Vocabulary class. \n",
        "\n",
        "The Vocabulary class not only manages this bijection — __allowing the user to add new tokens and have the index autoincrement__ —but also handles a special token called __UNK__,which stands for \"unknown.\" By using the UNK token, we can __handle tokens at test time that were never seen in training__ (for instance, you might encounter words that were not encountered in the training dataset). \n",
        "\n",
        "As we will see in the Vectorizer next, we will even explicitly restrict infrequent tokens from our Vocabulary so that there are UNK tokens in our training routine. This is essential in limiting the memory used by the Vocabulary class. \n",
        "\n",
        "The expected behavior is that `add_token()` is called to add new tokens to the Vocabulary, `lookup_token()` when retrieving the index for a token, and `lookup_index()` when retrieving the token corresponding to a specific index.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBaAE3k_NAUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Vocabulary(object):\n",
        "    \"\"\"Class to process text and extract vocabulary for mapping\"\"\"\n",
        "\n",
        "    def __init__(self, token_to_idx=None, add_unk=True, unk_token=\"<UNK>\"):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            token_to_idx (dict): a pre-existing map of tokens to indices\n",
        "            add_unk (bool): a flag that indicates whether to add the UNK token\n",
        "            unk_token (str): the UNK token to add into the Vocabulary\n",
        "        \"\"\"\n",
        "\n",
        "        # Mapping and reverse mapping token -> idx and idx -> token\n",
        "        if token_to_idx is None:\n",
        "            token_to_idx = {}\n",
        "        self._token_to_idx = token_to_idx\n",
        "\n",
        "        self._idx_to_token = {idx: token \n",
        "                              for token, idx in self._token_to_idx.items()}\n",
        "        \n",
        "        self._add_unk = add_unk\n",
        "        self._unk_token = unk_token\n",
        "        self.unk_index = -1\n",
        "        if add_unk:\n",
        "            self.unk_index = self.add_token(unk_token) \n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        \"\"\" instantiates the Vocabulary from a serialized dictionary \"\"\"\n",
        "        return cls(**contents)\n",
        "        # Note the index for UNK\n",
        "        self.unk_index = -1\n",
        "        if add_unk:\n",
        "            self.unk_index = self.add_token(unk_token) \n",
        "        \n",
        "\n",
        "    # SO THIS METHOD AND THE FOLLOWING THREE BASICALLY THE KEY TO THIS CLASS\n",
        "    # PUT \n",
        "    # PUT MANY\n",
        "    # GET USING TOKEN\n",
        "    # GET USING INDEX\n",
        "    def add_token(self, token):\n",
        "        \"\"\"Update mapping dicts based on the token.\n",
        "\n",
        "        Args:\n",
        "            token (str): the item to add into the Vocabulary\n",
        "        Returns:\n",
        "            index (int): the integer corresponding to the token\n",
        "        \"\"\"\n",
        "        if token in self._token_to_idx:\n",
        "            index = self._token_to_idx[token]\n",
        "        else:\n",
        "            index = len(self._token_to_idx)\n",
        "            self._token_to_idx[token] = index\n",
        "            self._idx_to_token[index] = token\n",
        "        return index\n",
        "    \n",
        "    def add_many(self, tokens):\n",
        "        \"\"\"Add a list of tokens into the Vocabulary\n",
        "        \n",
        "        Args:\n",
        "            tokens (list): a list of string tokens\n",
        "        Returns:\n",
        "            indices (list): a list of indices corresponding to the tokens\n",
        "        \"\"\"\n",
        "        # Uses the previous method\n",
        "        return [self.add_token(token) for token in tokens]\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        \"\"\"Retrieve the index associated with the token \n",
        "          or the UNK index if token isn't present.\n",
        "        \n",
        "        Args:\n",
        "            token (str): the token to look up \n",
        "        Returns:\n",
        "            index (int): the index corresponding to the token\n",
        "        Notes:\n",
        "            `unk_index` needs to be >=0 (having been added into the Vocabulary) \n",
        "              for the UNK functionality \n",
        "        \"\"\"\n",
        "        if self.unk_index >= 0:\n",
        "            return self._token_to_idx.get(token, self.unk_index)\n",
        "        else:\n",
        "            return self._token_to_idx[token]\n",
        "\n",
        "    def lookup_index(self, index):\n",
        "        \"\"\"Return the token associated with the index\n",
        "        \n",
        "        Args: \n",
        "            index (int): the index to look up\n",
        "        Returns:\n",
        "            token (str): the token corresponding to the index\n",
        "        Raises:\n",
        "            KeyError: if the index is not in the Vocabulary\n",
        "        \"\"\"\n",
        "        if index not in self._idx_to_token:\n",
        "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
        "        return self._idx_to_token[index]\n",
        "\n",
        "    # BESIDES INIT, THESE ARE THE STANDARD METHODS YOU WOULD DEFINE FOR ANY CLASS\n",
        "    # STR\n",
        "    # LEN\n",
        "    # TO SERIALIZABLE\n",
        "    # FROM SERIALIZABLE\n",
        "    def __str__(self):\n",
        "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._token_to_idx)\n",
        "\n",
        "    def to_serializable(self):\n",
        "      \"\"\" returns a dictionary that can be serialized \"\"\"\n",
        "      return {'token_to_idx': self._token_to_idx, \n",
        "              'add_unk': self._add_unk, \n",
        "              'unk_token': self._unk_token}\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "      \"\"\" instantiates the Vocabulary from a serialized dictionary \"\"\"\n",
        "      return cls(**contents)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iL6ao-5NCnv",
        "colab_type": "text"
      },
      "source": [
        "### Vectorizer - This is specific to each problem\n",
        "\n",
        "The second stage is to __iterate through the tokens of an input data point and convert each token to its integer form__. The result of this iteration should be a __vector__. Because this vector will be combined with vectors from other data points, there is a constraint that the vectors produced by the Vectorizer should always have the __same length__.\n",
        "\n",
        "To accomplish these goals, the Vectorizer class encapsulates the review Vocabulary, which maps words in the review to integers. \n",
        "\n",
        "The Vectorizer utilizes Python’s @classmethod decorator for the method `from_dataframe()` to indicate __an entry point to instantiating the Vectorizer__. The method from_dataframe() __iterates over the rows of a Pandas DataFrame__ with two goals. \n",
        "  *  first goal is to __count the frequency of all tokens present in the dataset__. \n",
        "  * The second goal is to __create a Vocabulary that only uses tokens that are as frequent as a provided keyword argument to the method, cutoff__\n",
        "\n",
        "Effectively, this method is __finding all words that occur at least cutoff times and adding them to the Vocabulary__. Because the UNK token is also added to the Vocabulary, __any words that are not added will have the unk_index__ when the Vocabulary’s lookup_token() method is called.\n",
        "\n",
        "The method `vectorize()` encapsulates the __core functionality__ of the Vectorizer. It takes as an argument a __string representing a review and returns a vectorized representation of the review__.\n",
        "\n",
        "We use the collapsed one-hot representation. This representation creates a __binary vector__ — a vector of 1s and 0s —that has a length equal to the size of the Vocabulary. The __binary vector has 1 in the locations that correspond to the words in the review__. Note that this representation has some limitations. \n",
        "  * The first is that it is __sparse__ — the number of unique words in the review will always be far less than the number of unique words in the Vocabulary.\n",
        "  * The second is that it __discards the order__ in which the words appeared in the review (the “bag of words” approach). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhwVjLsUOnsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReviewVectorizer(object):\n",
        "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"\n",
        "    def __init__(self, review_vocab, rating_vocab):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            review_vocab (Vocabulary): maps words to integers\n",
        "            rating_vocab (Vocabulary): maps class labels to integers\n",
        "        \"\"\"\n",
        "        # CLASSIFICATION HAS TWO: THE ACTUAL TEXT AND THE CLASS\n",
        "        self.review_vocab = review_vocab\n",
        "        self.rating_vocab = rating_vocab\n",
        "\n",
        "    def vectorize(self, review):\n",
        "        \"\"\"Create a collapsed one-hit vector for the review\n",
        "        \n",
        "        Args:\n",
        "            review (str): the review \n",
        "        Returns:\n",
        "            one_hot (np.ndarray): the collapsed one-hot encoding \n",
        "        \"\"\"\n",
        "        one_hot = np.zeros(len(self.review_vocab), dtype=np.float32)\n",
        "        \n",
        "        for token in review.split(\" \"):\n",
        "            if token not in string.punctuation:\n",
        "                one_hot[self.review_vocab.lookup_token(token)] = 1\n",
        "\n",
        "        return one_hot\n",
        "\n",
        "    @classmethod\n",
        "    def from_dataframe(cls, review_df, cutoff=25):\n",
        "        \"\"\"Instantiate the vectorizer from the dataset dataframe\n",
        "        \n",
        "        Args:\n",
        "            review_df (pandas.DataFrame): the review dataset\n",
        "            cutoff (int): the parameter for frequency-based filtering\n",
        "        Returns:\n",
        "            an instance of the ReviewVectorizer\n",
        "        \"\"\"\n",
        "        review_vocab = Vocabulary(add_unk=True)\n",
        "        rating_vocab = Vocabulary(add_unk=False)\n",
        "        \n",
        "        # Add ratings\n",
        "        for rating in sorted(set(review_df.rating)):\n",
        "            rating_vocab.add_token(rating)\n",
        "\n",
        "        # Add top words if count > provided count\n",
        "        word_counts = Counter()\n",
        "        for review in review_df.review:\n",
        "            for word in review.split(\" \"):\n",
        "                if word not in string.punctuation:\n",
        "                    word_counts[word] += 1\n",
        "               \n",
        "        for word, count in word_counts.items():\n",
        "            if count > cutoff:\n",
        "                review_vocab.add_token(word)\n",
        "\n",
        "        return cls(review_vocab, rating_vocab)\n",
        "\n",
        "    # THIS IS STANDARD METHOD\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        \"\"\"Instantiate a ReviewVectorizer from a serializable dictionary\n",
        "        \n",
        "        Args:\n",
        "            contents (dict): the serializable dictionary\n",
        "        Returns:\n",
        "            an instance of the ReviewVectorizer class\n",
        "        \"\"\"\n",
        "        review_vocab = Vocabulary.from_serializable(contents['review_vocab'])\n",
        "        rating_vocab =  Vocabulary.from_serializable(contents['rating_vocab'])\n",
        "\n",
        "        return cls(review_vocab=review_vocab, rating_vocab=rating_vocab)\n",
        "\n",
        "    def to_serializable(self):\n",
        "        \"\"\"Create the serializable dictionary for caching\n",
        "        \n",
        "        Returns:\n",
        "            contents (dict): the serializable dictionary\n",
        "        \"\"\"\n",
        "        return {'review_vocab': self.review_vocab.to_serializable(),\n",
        "                'rating_vocab': self.rating_vocab.to_serializable()}"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoyPek40kEEY",
        "colab_type": "text"
      },
      "source": [
        "### Dataloader\n",
        "* The final stage of the text-to-vectorized-minibatch pipeline is to actually group the vectorized data points. \n",
        "* Because grouping into minibatches is a vital part of training neural networks, PyTorch provides a built-in class called DataLoader for coordinating the process. \n",
        "* The DataLoader class is instantiated by providing a PyTorch Dataset (such as the ReviewDataset defined for this example), a batch_size, and a handful of other keyword arguments. \n",
        "* The resulting object is a Python iterator that groups and collates the data points provided in the Dataset.\n",
        "* We wrap the DataLoader in a generate_batches() function, which is a generator to conveniently switch the data between the CPU and the GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOB7IzCPk1va",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, review_df, vectorizer):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            review_df (pandas.DataFrame): the dataset\n",
        "            vectorizer (ReviewVectorizer): vectorizer instantiated from dataset\n",
        "        \"\"\"\n",
        "        self.review_df = review_df\n",
        "        self._vectorizer = vectorizer\n",
        "\n",
        "        self.train_df = self.review_df[self.review_df.split=='train']\n",
        "        self.train_size = len(self.train_df)\n",
        "\n",
        "        self.val_df = self.review_df[self.review_df.split=='val']\n",
        "        self.validation_size = len(self.val_df)\n",
        "\n",
        "        self.test_df = self.review_df[self.review_df.split=='test']\n",
        "        self.test_size = len(self.test_df)\n",
        "\n",
        "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
        "                             'val': (self.val_df, self.validation_size),\n",
        "                             'test': (self.test_df, self.test_size)}\n",
        "\n",
        "        self.set_split('train')\n",
        "\n",
        "    @classmethod\n",
        "    def load_dataset_and_make_vectorizer(cls, review_csv):\n",
        "        \"\"\"Load dataset and make a new vectorizer from scratch\n",
        "        \n",
        "        Args:\n",
        "            review_csv (str): location of the dataset\n",
        "        Returns:\n",
        "            an instance of ReviewDataset\n",
        "        \"\"\"\n",
        "        review_df = pd.read_csv(review_csv)\n",
        "        train_review_df = review_df[review_df.split=='train']\n",
        "        return cls(review_df, ReviewVectorizer.from_dataframe(train_review_df))\n",
        "    \n",
        "    @classmethod\n",
        "    def load_dataset_and_load_vectorizer(cls, review_csv, vectorizer_filepath):\n",
        "        \"\"\"Load dataset and the corresponding vectorizer. \n",
        "        Used in the case in the vectorizer has been cached for re-use\n",
        "        \n",
        "        Args:\n",
        "            review_csv (str): location of the dataset\n",
        "            vectorizer_filepath (str): location of the saved vectorizer\n",
        "        Returns:\n",
        "            an instance of ReviewDataset\n",
        "        \"\"\"\n",
        "        review_df = pd.read_csv(review_csv)\n",
        "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
        "        return cls(review_df, vectorizer)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_vectorizer_only(vectorizer_filepath):\n",
        "        \"\"\"a static method for loading the vectorizer from file\n",
        "        \n",
        "        Args:\n",
        "            vectorizer_filepath (str): the location of the serialized vectorizer\n",
        "        Returns:\n",
        "            an instance of ReviewVectorizer\n",
        "        \"\"\"\n",
        "        with open(vectorizer_filepath) as fp:\n",
        "            return ReviewVectorizer.from_serializable(json.load(fp))\n",
        "\n",
        "    def save_vectorizer(self, vectorizer_filepath):\n",
        "        \"\"\"saves the vectorizer to disk using json\n",
        "        \n",
        "        Args:\n",
        "            vectorizer_filepath (str): the location to save the vectorizer\n",
        "        \"\"\"\n",
        "        with open(vectorizer_filepath, \"w\") as fp:\n",
        "            json.dump(self._vectorizer.to_serializable(), fp)\n",
        "\n",
        "    def get_vectorizer(self):\n",
        "        \"\"\" returns the vectorizer \"\"\"\n",
        "        return self._vectorizer\n",
        "\n",
        "    def set_split(self, split=\"train\"):\n",
        "        \"\"\" selects the splits in the dataset using a column in the dataframe \n",
        "        \n",
        "        Args:\n",
        "            split (str): one of \"train\", \"val\", or \"test\"\n",
        "        \"\"\"\n",
        "        self._target_split = split\n",
        "        self._target_df, self._target_size = self._lookup_dict[split]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._target_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"the primary entry point method for PyTorch datasets\n",
        "        \n",
        "        Args:\n",
        "            index (int): the index to the data point \n",
        "        Returns:\n",
        "            a dictionary holding the data point's features (x_data) and label (y_target)\n",
        "        \"\"\"\n",
        "        row = self._target_df.iloc[index]\n",
        "\n",
        "        review_vector = self._vectorizer.vectorize(row.review)\n",
        "\n",
        "        rating_index = self._vectorizer.rating_vocab.lookup_token(row.rating)\n",
        "\n",
        "        return {'x_data': review_vector,\n",
        "                'y_target': rating_index}\n",
        "\n",
        "    def get_num_batches(self, batch_size):\n",
        "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
        "        \n",
        "        Args:\n",
        "            batch_size (int)\n",
        "        Returns:\n",
        "            number of batches in the dataset\n",
        "        \"\"\"\n",
        "        return len(self) # batch_size "
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE70UmwLk8td",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_batches(dataset, batch_size, shuffle=True,\n",
        "                     drop_last=True, device=\"cpu\"):\n",
        "    \"\"\"\n",
        "    A generator function which wraps the PyTorch DataLoader. It will \n",
        "      ensure each tensor is on the write device location.\n",
        "    \"\"\"\n",
        "    dataloader = DataLoader(\n",
        "        dataset=dataset, \n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle, \n",
        "        drop_last=drop_last\n",
        "    )\n",
        "\n",
        "    for data_dict in dataloader:\n",
        "        out_data_dict = {}\n",
        "        for name, tensor in data_dict.items():\n",
        "            out_data_dict[name] = data_dict[name].to(device)\n",
        "        yield out_data_dict\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLXmPyDFr5oB",
        "colab_type": "text"
      },
      "source": [
        "## Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qp-veJStabg",
        "colab_type": "text"
      },
      "source": [
        "### Helper functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1y_wv7ls1dZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_train_state(args):\n",
        "    return {'stop_early': False,\n",
        "            'early_stopping_step': 0,\n",
        "            'early_stopping_best_val': 1e8,\n",
        "            'learning_rate': args.learning_rate,\n",
        "            'epoch_index': 0,\n",
        "            'train_loss': [],\n",
        "            'train_acc': [],\n",
        "            'val_loss': [],\n",
        "            'val_acc': [],\n",
        "            'test_loss': -1,\n",
        "            'test_acc': -1,\n",
        "            'model_filename': args.model_state_file}\n",
        "\n",
        "\n",
        "def update_train_state(args, model, train_state):\n",
        "    \"\"\"Handle the training state updates.\n",
        "\n",
        "    Components:\n",
        "     - Early Stopping: Prevent overfitting.\n",
        "     - Model Checkpoint: Model is saved if the model is better\n",
        "\n",
        "    :param args: main arguments\n",
        "    :param model: model to train\n",
        "    :param train_state: a dictionary representing the training state values\n",
        "    :returns:\n",
        "        a new train_state\n",
        "    \"\"\"\n",
        "\n",
        "    # Save one model at least\n",
        "    if train_state['epoch_index'] == 0:\n",
        "        torch.save(model.state_dict(), train_state['model_filename'])\n",
        "        train_state['stop_early'] = False\n",
        "\n",
        "    # Save model if performance improved\n",
        "    elif train_state['epoch_index'] >= 1:\n",
        "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
        "\n",
        "        # If loss worsened\n",
        "        if loss_t >= train_state['early_stopping_best_val']:\n",
        "            # Update step\n",
        "            train_state['early_stopping_step'] += 1\n",
        "        # Loss decreased\n",
        "        else:\n",
        "            # Save the best model\n",
        "            if loss_t < train_state['early_stopping_best_val']:\n",
        "                torch.save(model.state_dict(), train_state['model_filename'])\n",
        "\n",
        "            # Reset early stopping step\n",
        "            train_state['early_stopping_step'] = 0\n",
        "\n",
        "        # Stop early ?\n",
        "        train_state['stop_early'] = \\\n",
        "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
        "\n",
        "    return train_state\n",
        "\n",
        "\n",
        "def compute_accuracy(y_pred, y_target):\n",
        "    y_target = y_target.cpu()\n",
        "    y_pred_indices = (torch.sigmoid(y_pred)>0.5).cpu().long()#.max(dim=1)[1]\n",
        "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
        "    return n_correct / len(y_pred_indices) * 100\n",
        "\n",
        "\n",
        "def set_seed_everywhere(seed, cuda):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if cuda:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def handle_dirs(dirpath):\n",
        "    if not os.path.exists(dirpath):\n",
        "        os.makedirs(dirpath)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vzFkW6dszZ9",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xky4zFyOsOBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReviewClassifier(nn.Module):\n",
        "    \"\"\" a simple perceptron based classifier \"\"\"\n",
        "    def __init__(self, num_features):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            num_features (int): the size of the input feature vector\n",
        "        \"\"\"\n",
        "        super(ReviewClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(in_features=num_features, \n",
        "                             out_features=1)\n",
        "\n",
        "    def forward(self, x_in, apply_sigmoid=False):\n",
        "        \"\"\"The forward pass of the classifier\n",
        "        \n",
        "        Args:\n",
        "            x_in (torch.Tensor): an input data tensor. \n",
        "                x_in.shape should be (batch, num_features)\n",
        "            apply_sigmoid (bool): a flag for the sigmoid activation\n",
        "                should be false if used with the Cross Entropy losses\n",
        "        Returns:\n",
        "            the resulting tensor. tensor.shape should be (batch,)\n",
        "        \"\"\"\n",
        "        y_out = self.fc1(x_in).squeeze()\n",
        "        if apply_sigmoid:\n",
        "            y_out = torch.sigmoid(y_out)\n",
        "        return y_out"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJLyVupJsX2j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "ebabe867-f3c4-49d9-a797-4bb04a1de1c3"
      },
      "source": [
        "args = Namespace(\n",
        "    # Data and Path information\n",
        "    frequency_cutoff=25,\n",
        "    model_state_file='model.pth',\n",
        "    review_csv='yelp_with_splits_full.csv',\n",
        "    # review_csv='data/yelp/reviews_with_splits_full.csv',\n",
        "    save_dir='./',\n",
        "    vectorizer_file='vectorizer.json',\n",
        "    # No Model hyper parameters\n",
        "    # Training hyper parameters\n",
        "    batch_size=128,\n",
        "    early_stopping_criteria=5,\n",
        "    learning_rate=0.001,\n",
        "    num_epochs=100,\n",
        "    seed=1337,\n",
        "    # Runtime options\n",
        "    catch_keyboard_interrupt=True,\n",
        "    cuda=True,\n",
        "    expand_filepaths_to_save_dir=True,\n",
        "    reload_from_files=False,\n",
        ")\n",
        "\n",
        "if args.expand_filepaths_to_save_dir:\n",
        "    args.vectorizer_file = os.path.join(args.save_dir,\n",
        "                                        args.vectorizer_file)\n",
        "\n",
        "    args.model_state_file = os.path.join(args.save_dir,\n",
        "                                         args.model_state_file)\n",
        "    \n",
        "    print(\"Expanded filepaths: \")\n",
        "    print(\"\\t{}\".format(args.vectorizer_file))\n",
        "    print(\"\\t{}\".format(args.model_state_file))\n",
        "    \n",
        "# Check CUDA\n",
        "if not torch.cuda.is_available():\n",
        "    args.cuda = False\n",
        "\n",
        "print(\"Using CUDA: {}\".format(args.cuda))\n",
        "\n",
        "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "\n",
        "# Set seed for reproducibility\n",
        "set_seed_everywhere(args.seed, args.cuda)\n",
        "\n",
        "# handle dirs\n",
        "handle_dirs(args.save_dir)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Expanded filepaths: \n",
            "\t./vectorizer.json\n",
            "\t./model.pth\n",
            "Using CUDA: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3uu0yEKx1Cz",
        "colab_type": "text"
      },
      "source": [
        "### Initializations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgMDR3AVx6QW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "8cce8cb1-1674-4b9d-ff43-be217e060732"
      },
      "source": [
        "if args.reload_from_files:\n",
        "    # training from a checkpoint\n",
        "    print(\"Loading dataset and vectorizer\")\n",
        "    dataset = ReviewDataset.load_dataset_and_load_vectorizer(args.review_csv,\n",
        "                                                            args.vectorizer_file)\n",
        "else:\n",
        "    print(\"Loading dataset and creating vectorizer\")\n",
        "    # create dataset and vectorizer\n",
        "    dataset = ReviewDataset.load_dataset_and_make_vectorizer(args.review_csv)\n",
        "    dataset.save_vectorizer(args.vectorizer_file)    \n",
        "vectorizer = dataset.get_vectorizer()\n",
        "\n",
        "classifier = ReviewClassifier(num_features=len(vectorizer.review_vocab))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading dataset and creating vectorizer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWceraxUzzrw",
        "colab_type": "text"
      },
      "source": [
        "### Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_8qzRrF0CCv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253,
          "referenced_widgets": [
            "4077f5c5e44746f28ad422c6518eb5f3",
            "7ced6313fb5945748b666d2de08d158a",
            "4865f7a04d2546e5920d1e5901875729",
            "9e5a7771dac244e68d97783ddfca88bd",
            "856c668c0cc64e56a4a9cf2ed7078f71",
            "5f5b053a4ebe4c79903ae64a028ce42d",
            "fc6e7d61af014dd7961b607942b7b7c0",
            "59734f5c209b4563925b72c8495efaab",
            "1b8fbd1abaf64cacbd21b828a0ac1016",
            "09e78ba9c5234e3982e41139ddfe3167",
            "9d9d60871ed34472af0b3ff46f81d8e6",
            "bcb24122ac264f80875e923420e33957",
            "56f126cd5ca148c4b60a47779bc68a07",
            "5e8241a070124ba3ba7bfb07a7817db4",
            "cc17b1452dca4dbea21c74d6af1ba6e4",
            "56466eec01ee4ca090fa3615707cd020",
            "13932c5ee63a46299660c8ab70012852",
            "97dc381f0dda43da9c666370ed4be383",
            "e9d39a028b934991be17f929d1dfc0a3",
            "e18de12173e44ea1a6821b7c3215607f",
            "7d107b957c8f400e9c5b140cfd313d3e",
            "70bbd740458246cbacdcd9f2bef437d2",
            "2d07d1b1141e42f79f7ebfc87fda2aa2",
            "beec5446dcda464db642ad268bbe72c4"
          ]
        },
        "outputId": "f81d02d4-d3ae-4415-e7a6-429da547357f"
      },
      "source": [
        "classifier = classifier.to(args.device)\n",
        "\n",
        "loss_func = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                                 mode='min', factor=0.5,\n",
        "                                                 patience=1)\n",
        "\n",
        "train_state = make_train_state(args)\n",
        "\n",
        "epoch_bar = tqdm_notebook(desc='training routine', \n",
        "                          total=args.num_epochs,\n",
        "                          position=0)\n",
        "\n",
        "dataset.set_split('train')\n",
        "train_bar = tqdm_notebook(desc='split=train',\n",
        "                          total=dataset.get_num_batches(args.batch_size), \n",
        "                          position=1, \n",
        "                          leave=True)\n",
        "dataset.set_split('val')\n",
        "val_bar = tqdm_notebook(desc='split=val',\n",
        "                        total=dataset.get_num_batches(args.batch_size), \n",
        "                        position=1, \n",
        "                        leave=True)\n",
        "\n",
        "try:\n",
        "    for epoch_index in range(args.num_epochs):\n",
        "        train_state['epoch_index'] = epoch_index\n",
        "\n",
        "        # Iterate over training dataset\n",
        "\n",
        "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
        "        dataset.set_split('train')\n",
        "        batch_generator = generate_batches(dataset, \n",
        "                                           batch_size=args.batch_size, \n",
        "                                           device=args.device)\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        classifier.train()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # the training routine is these 5 steps:\n",
        "\n",
        "            # --------------------------------------\n",
        "            # step 1. zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # step 2. compute the output\n",
        "            y_pred = classifier(x_in=batch_dict['x_data'].float())\n",
        "\n",
        "            # step 3. compute the loss\n",
        "            loss = loss_func(y_pred, batch_dict['y_target'].float())\n",
        "            loss_t = loss.item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            # step 4. use loss to produce gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # step 5. use optimizer to take gradient step\n",
        "            optimizer.step()\n",
        "            # -----------------------------------------\n",
        "            # compute the accuracy\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            # update bar\n",
        "            train_bar.set_postfix(loss=running_loss, \n",
        "                                  acc=running_acc, \n",
        "                                  epoch=epoch_index)\n",
        "            train_bar.update()\n",
        "\n",
        "        train_state['train_loss'].append(running_loss)\n",
        "        train_state['train_acc'].append(running_acc)\n",
        "\n",
        "        # Iterate over val dataset\n",
        "\n",
        "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
        "        dataset.set_split('val')\n",
        "        batch_generator = generate_batches(dataset, \n",
        "                                           batch_size=args.batch_size, \n",
        "                                           device=args.device)\n",
        "        running_loss = 0.\n",
        "        running_acc = 0.\n",
        "        classifier.eval()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "\n",
        "            # compute the output\n",
        "            y_pred = classifier(x_in=batch_dict['x_data'].float())\n",
        "\n",
        "            # step 3. compute the loss\n",
        "            loss = loss_func(y_pred, batch_dict['y_target'].float())\n",
        "            loss_t = loss.item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            # compute the accuracy\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "            \n",
        "            val_bar.set_postfix(loss=running_loss, \n",
        "                                acc=running_acc, \n",
        "                                epoch=epoch_index)\n",
        "            val_bar.update()\n",
        "\n",
        "        train_state['val_loss'].append(running_loss)\n",
        "        train_state['val_acc'].append(running_acc)\n",
        "\n",
        "        train_state = update_train_state(args=args, model=classifier,\n",
        "                                         train_state=train_state)\n",
        "\n",
        "        scheduler.step(train_state['val_loss'][-1])\n",
        "\n",
        "        train_bar.n = 0\n",
        "        val_bar.n = 0\n",
        "        epoch_bar.update()\n",
        "\n",
        "        if train_state['stop_early']:\n",
        "            break\n",
        "\n",
        "        train_bar.n = 0\n",
        "        val_bar.n = 0\n",
        "        epoch_bar.update()\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Exiting loop\")\n",
        "\n",
        "\n",
        "# compute the loss & accuracy on the test set using the best available model\n",
        "\n",
        "classifier.load_state_dict(torch.load(train_state['model_filename']))\n",
        "classifier = classifier.to(args.device)\n",
        "\n",
        "dataset.set_split('test')\n",
        "batch_generator = generate_batches(dataset, \n",
        "                                   batch_size=args.batch_size, \n",
        "                                   device=args.device)\n",
        "running_loss = 0.\n",
        "running_acc = 0.\n",
        "classifier.eval()\n",
        "\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\n",
        "    # compute the output\n",
        "    y_pred = classifier(x_in=batch_dict['x_data'].float())\n",
        "\n",
        "    # compute the loss\n",
        "    loss = loss_func(y_pred, batch_dict['y_target'].float())\n",
        "    loss_t = loss.item()\n",
        "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "    # compute the accuracy\n",
        "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "train_state['test_loss'] = running_loss\n",
        "train_state['test_acc'] = running_acc\n",
        "\n",
        "print(\"Test loss: {:.3f}\".format(train_state['test_loss']))\n",
        "print(\"Test Accuracy: {:.2f}\".format(train_state['test_acc']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4077f5c5e44746f28ad422c6518eb5f3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='training routine', style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b8fbd1abaf64cacbd21b828a0ac1016",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='split=train', max=392000.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13932c5ee63a46299660c8ab70012852",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='split=val', max=168000.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}