{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FastAITextProc.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNEScBRfv6jE/hhZURfGHLH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vikramkrishnan9885/MyColab/blob/master/fastai/FastAITextProc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9puWtp0sm9-V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "287d4495-acd3-40bd-8f48-b1a40044db21"
      },
      "source": [
        "import fastai\n",
        "fastai.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.0.61'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# validate access to GPU\n",
        "\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rkXBnXs0EFX",
        "outputId": "b0e287c5-c877-4494-9a88-862dd38f2f36"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jan 22 08:04:24 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training a deep learning language model with a curated IMDb text dataset"
      ],
      "metadata": {
        "id": "qru5-qWF0X2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uqq fastbook"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5Yr3r6I1L9g",
        "outputId": "a05b0f95-d2de-4f05-f2b8-f37c774d5d2a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 720 kB 7.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 46 kB 5.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 34.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 189 kB 71.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 6.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 51 kB 453 kB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fastbook\n",
        "fastbook.setup_book()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWFAevf21A1-",
        "outputId": "5f2c6e7b-5dfc-4e33-f694-6c828556d1c7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastbook import *\n",
        "from fastai.text.all import *"
      ],
      "metadata": {
        "id": "lHnByoTf1PoT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define timestamp string for saving models\n",
        "modifier = \"aug13_2021\""
      ],
      "metadata": {
        "id": "-d1eq6dk1b62"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# create path object\n",
        "path = untar_data(URLs.IMDB)\n",
        "path.ls()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "QyOrZ6Rw1exM",
        "outputId": "eb12c569-4347-4819-e55f-529b7baa2c14"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='144441344' class='' max='144440600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [144441344/144440600 00:04<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 16.3 s, sys: 8.13 s, total: 24.4 s\n",
            "Wall time: 28.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# create TextDataLoaders object\n",
        "get_imdb = partial(get_text_files, folders=['train', 'test', 'unsup'])\n",
        "dls = TextDataLoaders.from_folder(path, valid = 'test', is_lm=True, bs=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "6ifX1c-91i0E",
        "outputId": "31b5f075-4118-4672-e827-1e8d1827adac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 43.9 s, sys: 10.6 s, total: 54.5 s\n",
            "Wall time: 4min 28s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are the arguments for the definition of the TextDataLoaders object:\n",
        "* **path:** The path object (associated with the IMDb curated dataset) that you defined earlier in the notebook.\n",
        "* **valid:** Identifies the folder in the dataset's directory structure that will be used to assessy the performance of the model: imdb/test.\n",
        "* **is_lm:** Set to True to indicate that this object will be used for a language model (as opposed to a text classifier).\n",
        "* **bs:** Specifies the batch size.\n",
        "\n",
        "**Note:**\n",
        "\n",
        "When you are training a language model with a large dataset such as IMDb, adjusting the bs value to be lower than the default batch size of 64 will be essential for avoiding memory errors, and that is why it is set to 16 in this TextDataLoaders definition.\n",
        "\n",
        "Run the following command to show a couple of items from a sample batch:\n",
        "\n",
        "dls.show_batch(max_n=2)\n",
        "The max_n argument specifies the number of sample batch items to show."
      ],
      "metadata": {
        "id": "4UtxXkfU1u8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dls.show_batch(max_n=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "r34HbiKy23tw",
        "outputId": "8476be8f-84fb-4290-a609-080bc7312795"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xxbos xxmaj it holds very true to the original manga of the same name , aka ( tramps xxmaj like xxmaj us in the xxup u.s ) but it can still be enjoyed even if you have n't read the manga . xxmaj it 's a different kind of tail , showing a strong and independent woman who hurts just like everyone else . xxmaj however , because of her outward strength</td>\n",
              "      <td>xxmaj it holds very true to the original manga of the same name , aka ( tramps xxmaj like xxmaj us in the xxup u.s ) but it can still be enjoyed even if you have n't read the manga . xxmaj it 's a different kind of tail , showing a strong and independent woman who hurts just like everyone else . xxmaj however , because of her outward strength ,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the historical dust . xxmaj the terrain looks like an interior tribal reservation of no particular importance to the coastal xxunk where industry dwells . xxmaj yet , it 's also a region most likely to survive anything like a destructive last wave . xxmaj perhaps there 's something about past and future to think about here . \\n\\n xxmaj anyway , this is a really good movie that will probably stay</td>\n",
              "      <td>historical dust . xxmaj the terrain looks like an interior tribal reservation of no particular importance to the coastal xxunk where industry dwells . xxmaj yet , it 's also a region most likely to survive anything like a destructive last wave . xxmaj perhaps there 's something about past and future to think about here . \\n\\n xxmaj anyway , this is a really good movie that will probably stay with</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# define and train model\n",
        "learn = language_model_learner(dls,AWD_LSTM,metrics=accuracy).to_fp32()\n",
        "learn.fine_tune(1, 1e-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "AU7U5zMl26zn",
        "outputId": "2538e1fc-c2b9-44db-f896-3a452fe3b84c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>6.321066</td>\n",
              "      <td>5.738266</td>\n",
              "      <td>0.158222</td>\n",
              "      <td>29:33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.554787</td>\n",
              "      <td>4.394859</td>\n",
              "      <td>0.270794</td>\n",
              "      <td>33:39</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1h 2min 35s, sys: 37.2 s, total: 1h 3min 12s\n",
            "Wall time: 1h 3min 14s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following cell to exercise the language model you just trained:\n",
        "\n",
        "Here are the arguments for this invocation of the language model:\n",
        "1. The input text sample \"what comes next\" (first argument) is the phrase that the model will complete. The language model will predict what words should follow this phrase.\n",
        "2. n_words: This is the number of words that the language model is supposed to predict to complete the input phrase."
      ],
      "metadata": {
        "id": "Rijuys0W3YKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn.predict(\"what comes next\", n_words=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fxU8lpz53cH5",
        "outputId": "4cee2d10-35a7-4b6e-dfc5-01c6baf1e2d5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'what comes next other in the world eating mutiny without a mental hospital would hit it on the Wall film - i'"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "2McDwuvnDFih",
        "outputId": "9b0add44-5e6f-4a93-c42d-eb7f4b2acba7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "SequentialRNN (Input shape: 8 x 72)\n",
              "============================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "============================================================================\n",
              "                     8 x 72 x 1152       \n",
              "LSTM                                                           \n",
              "LSTM                                                           \n",
              "____________________________________________________________________________\n",
              "                     8 x 72 x 400        \n",
              "LSTM                                                           \n",
              "RNNDropout                                                     \n",
              "RNNDropout                                                     \n",
              "RNNDropout                                                     \n",
              "____________________________________________________________________________\n",
              "                     8 x 72 x 60008      \n",
              "Linear                                    24063208   True      \n",
              "RNNDropout                                                     \n",
              "____________________________________________________________________________\n",
              "\n",
              "Total params: 24,063,208\n",
              "Total trainable params: 24,063,208\n",
              "Total non-trainable params: 0\n",
              "\n",
              "Optimizer used: <function Adam at 0x7f4c19ceadd0>\n",
              "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
              "\n",
              "Model unfrozen\n",
              "\n",
              "Callbacks:\n",
              "  - TrainEvalCallback\n",
              "  - ModelResetter\n",
              "  - RNNCallback\n",
              "  - Recorder\n",
              "  - ProgressCallback"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn.model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeWSI4agDJQj",
        "outputId": "7099edd2-b548-47a9-9256-a5be3649484f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequentialRNN(\n",
              "  (0): AWD_LSTM(\n",
              "    (encoder): Embedding(60008, 400, padding_idx=1)\n",
              "    (encoder_dp): EmbeddingDropout(\n",
              "      (emb): Embedding(60008, 400, padding_idx=1)\n",
              "    )\n",
              "    (rnns): ModuleList(\n",
              "      (0): WeightDropout(\n",
              "        (module): LSTM(400, 1152, batch_first=True)\n",
              "      )\n",
              "      (1): WeightDropout(\n",
              "        (module): LSTM(1152, 1152, batch_first=True)\n",
              "      )\n",
              "      (2): WeightDropout(\n",
              "        (module): LSTM(1152, 400, batch_first=True)\n",
              "      )\n",
              "    )\n",
              "    (input_dp): RNNDropout()\n",
              "    (hidden_dps): ModuleList(\n",
              "      (0): RNNDropout()\n",
              "      (1): RNNDropout()\n",
              "      (2): RNNDropout()\n",
              "    )\n",
              "  )\n",
              "  (1): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=60008, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keep_path = learn.path\n",
        "\n",
        "# workaround to make path writeable\n",
        "learn.path = Path('/notebooks/temp')\n",
        "\n",
        "learn.path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CWKtuI2Cpvc",
        "outputId": "ba637592-0b72-4b5e-f874-d1aaaac7b0b9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('/notebooks/temp')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn.model_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xwz3zTtgDaM4",
        "outputId": "82ad1ad7-099d-4f9c-f8e6-c8906e52fb85"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'models'"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn.save('lm_'+modifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuEQ32pyDePD",
        "outputId": "d82f176a-2504-4059-969c-88b26a1cad4c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('/notebooks/temp/models/lm_aug13_2021.pth')"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# workaround to save encoder - need to do this to later load encoder for classifier\n",
        "learn.save_encoder('ft_'+modifier)"
      ],
      "metadata": {
        "id": "NDCpAt18D5mR"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.export('lm_model_'+modifier+'.pkl')"
      ],
      "metadata": {
        "id": "FWVgae0QD8gP"
      },
      "execution_count": 39,
      "outputs": []
    }
  ]
}